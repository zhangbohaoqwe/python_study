{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be900e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import os,PIL,pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d9a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\"if torch.cuda.is_available()else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78ef32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carzing',\n",
       " 'inclusion',\n",
       " 'patches',\n",
       " 'pittted_surface',\n",
       " 'rolled_in_scale',\n",
       " 'scratch']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir=\"IMAGES/\"\n",
    "data_dir=pathlib.Path(data_dir)\n",
    "data_paths=list(data_dir.glob(\"*\"))\n",
    "classeName=[str(path).split(\"\\\\\")[1]for path in data_paths]\n",
    "classeName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db200c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1800\n",
       "    Root location: IMAGES/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=[224, 224], interpolation=bilinear)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_datadir=\"IMAGES/\"\n",
    "train_transforms=transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.485,0.456,0.406],\n",
    "    std=[0.229,0.224,0.225])\n",
    "])\n",
    "total_data=datasets.ImageFolder(total_datadir,transform=train_transforms)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9483f668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.Subset at 0x18d7b6c2438>,\n",
       " <torch.utils.data.dataset.Subset at 0x18d7b6c20f0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size=int(0.8*len(total_data))\n",
    "test_size=len(total_data)-train_size\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(total_data,[train_size,test_size])\n",
    "train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2534d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dl=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=1)\n",
    "test_dl=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6b1ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network_bn(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=57624, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network_bn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network_bn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(12)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        self.fc1 = nn.Linear(24*49*49, len(classeName))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) #220     \n",
    "        x = F.relu(self.bn2(self.conv2(x)))  #216  \n",
    "        x = F.relu(self.bn2(self.conv3(x))) #212\n",
    "        x = self.pool(x)        #106                \n",
    "        x = F.relu(self.bn4(self.conv4(x)))   #102  \n",
    "        x = F.relu(self.bn5(self.conv5(x)))  #98\n",
    "        x = self.pool(x)        #49                \n",
    "        x = x.view(-1, 24*49*49)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "model = Network_bn().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dacaa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "learn_rate=1e-4\n",
    "opt=torch.optim.Adam(model.parameters(),lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9649b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # 训练集的大小，一共60000张图片\n",
    "    num_batches = len(dataloader)   # 批次数目，1875（60000/32）\n",
    "\n",
    "    train_loss, train_acc = 0, 0  # 初始化训练损失和正确率\n",
    "    \n",
    "    for X, y in dataloader:  # 获取图片及其标签\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 计算预测误差\n",
    "        pred = model(X)          # 网络输出\n",
    "        loss = loss_fn(pred, y)  # 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # grad属性归零\n",
    "        loss.backward()        # 反向传播\n",
    "        optimizer.step()       # 每一步自动更新\n",
    "        \n",
    "        # 记录acc与loss\n",
    "        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "            \n",
    "    train_acc  /= size\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca5c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (dataloader, model, loss_fn):\n",
    "    size        = len(dataloader.dataset)  # 测试集的大小，一共10000张图片\n",
    "    num_batches = len(dataloader)          # 批次数目，313（10000/32=312.5，向上取整）\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # 当不进行训练时，停止梯度更新，节省计算内存消耗\n",
    "    with torch.no_grad():\n",
    "        for imgs, target in dataloader:\n",
    "            imgs, target = imgs.to(device), target.to(device)\n",
    "            \n",
    "            # 计算loss\n",
    "            target_pred = model(imgs)\n",
    "            loss        = loss_fn(target_pred, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "    test_acc  /= size\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5ecbf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_acc:70.1%, Train_loss:0.785, Test_acc:15.6%，Test_loss:5.682\n",
      "Epoch: 2, Train_acc:85.1%, Train_loss:0.439, Test_acc:35.0%，Test_loss:6.269\n",
      "Epoch: 3, Train_acc:93.5%, Train_loss:0.195, Test_acc:32.8%，Test_loss:7.207\n",
      "Epoch: 4, Train_acc:93.8%, Train_loss:0.178, Test_acc:32.2%，Test_loss:8.536\n",
      "Epoch: 5, Train_acc:95.5%, Train_loss:0.156, Test_acc:29.7%，Test_loss:8.687\n",
      "Epoch: 6, Train_acc:95.4%, Train_loss:0.130, Test_acc:29.7%，Test_loss:12.443\n",
      "Epoch: 7, Train_acc:97.2%, Train_loss:0.094, Test_acc:30.8%，Test_loss:12.524\n",
      "Epoch: 8, Train_acc:94.7%, Train_loss:0.159, Test_acc:31.1%，Test_loss:11.316\n",
      "Epoch: 9, Train_acc:96.4%, Train_loss:0.114, Test_acc:29.7%，Test_loss:15.867\n",
      "Epoch:10, Train_acc:98.7%, Train_loss:0.054, Test_acc:29.7%，Test_loss:14.691\n",
      "Epoch:11, Train_acc:99.0%, Train_loss:0.042, Test_acc:30.8%，Test_loss:12.294\n",
      "Epoch:12, Train_acc:99.0%, Train_loss:0.044, Test_acc:31.7%，Test_loss:14.164\n",
      "Epoch:13, Train_acc:98.5%, Train_loss:0.044, Test_acc:31.9%，Test_loss:15.387\n",
      "Epoch:14, Train_acc:95.6%, Train_loss:0.130, Test_acc:33.1%，Test_loss:15.115\n",
      "Epoch:15, Train_acc:94.8%, Train_loss:0.143, Test_acc:30.8%，Test_loss:16.983\n",
      "Epoch:16, Train_acc:97.4%, Train_loss:0.092, Test_acc:34.4%，Test_loss:15.884\n",
      "Epoch:17, Train_acc:98.2%, Train_loss:0.047, Test_acc:31.1%，Test_loss:18.094\n",
      "Epoch:18, Train_acc:99.2%, Train_loss:0.034, Test_acc:30.6%，Test_loss:18.296\n",
      "Epoch:19, Train_acc:98.0%, Train_loss:0.073, Test_acc:30.0%，Test_loss:13.376\n",
      "Epoch:20, Train_acc:99.2%, Train_loss:0.031, Test_acc:31.4%，Test_loss:15.649\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "train_loss=[]\n",
    "train_acc=[]\n",
    "test_loss=[]\n",
    "test_acc=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_train_acc,epoch_train_loss=train(train_dl,model,loss_fn,opt)\n",
    "    model.eval()\n",
    "    epoch_test_acc,epoch_test_loss=test(test_dl,model,loss_fn)\n",
    "    train_acc.append(epoch_train_acc)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    \n",
    "    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}')\n",
    "    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96da6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "classes=list(total_data.class_to_idx)\n",
    "def pred_one_image(image_path,model,transform,classes):\n",
    "    test_img=Image.open(image_path).convert(\"RGB\")\n",
    "    test_img=transform(test_img)\n",
    "    img=test_img.to(device).unsqueeze(0)\n",
    "    model.eval()\n",
    "    output=model(img)\n",
    "    _,pred=torch.max(output,1)\n",
    "    pred_class=classes[pred]\n",
    "    print(\"结果为：{}\".format(pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eefd5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"F:\\postgraduate\\deeplearning365\\8.pytorchweather\\model.pt\"\n",
    "torch.save(model.state_dict(),path)\n",
    "model.load_state_dict(torch.load(path,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e243251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果为：pittted_surface\n"
     ]
    }
   ],
   "source": [
    "pred_one_image(image_path=r\"F:\\postgraduate\\deeplearning365\\8.pytorchweather\\IMAGES\\patches\\patches_1.jpg\",model=model,transform=train_transforms,classes=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e7cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
